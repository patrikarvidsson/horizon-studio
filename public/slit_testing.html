
      <!doctype html>
        <html lang="en">
        <head>
          <meta charset="utf-8">
          <meta name="viewport" content="width=device-width,initial-scale=1">
          <meta name="robots" content="nofollow">
          <meta name="googlebot" content="none">
          <meta name="description" content="Notes on split testing">
          <meta name="author" content="Patrik Arvidsson">
          <meta name="generator" content="Horizon">
          <title>Slit Testing | Patrik Arvidsson</title>
          <style>:root{--c-primary: #4D89BF;--c-white: rgba(255,255,255,1);--c-black: rgba(0,0,0,1);--c-gray: rgba(0,0,0,0.6)}*{-webkit-font-smoothing:antialiased;font-smoothing:antialiased;text-rendering:optimizeLegibility}html{height:100%;font-size:100%}body{font:16px/1.6 sans-serif;font-weight:400;padding:1.27rem 1.62rem}main{max-width:60ch}#l{width:25px;height:25px;stroke-width:1.62em;stroke:currentColor}a,h1,h2,h3{font-weight:600}#l,a,body{color:var(--c-black)}a{text-decoration:none}a.external:after{content:"°"}a:hover{color:var(--c-primary)}h1,h2,h3{margin-top:1.62rem;line-height:1.5}h1{font-size:1.6em}h2{font-size:1.3em}nav ol{list-style-type:none;padding:0}figcaption,small,span{color:var(--c-gray)}figure{margin:0}img{max-width:100%}figcaption{font-size:90%}table{background:var(--c-black);color:var(--c-white);width:100%;font-size:14px;padding:.3rem .5rem;margin-bottom:2.27rem}table tr:first-of-type td{font-weight:600}table a{color:var(--c-white)}footer{margin-top:1.62rem;display:flex;align-items:center}footer a{font-weight:400;color:var(--c-black)}</style>
        </head><header><p><a href="methods.html">Methods</a> / Slit Testing</p><h1>Notes on split testing</h1></header><main><p>A/B testing, as it is commonly known as, is a way of comparing two versions of a web page or application against each other in order to see which one performs&nbsp;better.</p><p>It is an experiement where two or more variants are shown to users at random, and statistical analysis is used to determine which variation increases&nbsp;conversion.</p><p>This type of testing takes the guesswork away from the process, and enables data-informed decisions that shifts our conversations from thinking to&nbsp;knowing.</p><p>It is valuable in refining a working design, to find out what attracts users or helps them complete a given&nbsp;process.</p><h2>How it&nbsp;works</h2><p>Imagine you make a copy of one of your pages, and changes the location of the primary <dfn><abbr title="Call To Action">CTA</abbr></dfn> button in one of the&nbsp;pages.</p><p>You then present these two pages to the world, where half of your visiters see the original page (known as control) and the other half sees the modified page (the&nbsp;variation).</p><p>Engangement with each version is then measured and analyzed to determine which provided the most positive experience in terms of established conversion goals and&nbsp;KPIs.</p><h2>Advantages</h2><p>It is easy to implement in a production setting as there are third party tools which does most of the heavy lifting today. This makes it a quick way to test simple hypotheses you might have which can help you iterate quickly without taking too much of a&nbsp;risk.</p><p>Test doesn&rsquo;t have to be gracefully designed, or balanced for that matter and very simple statistical tests are necessary to crown a clear winner. It is also easy to patch-test by starting small and then continuously move up to larger parts of a website or&nbsp;app.</p><h2>Drawbacks</h2><p>A/B testing can take a longer time to set up compared to other forms of testing, even with third party services. Further, in order to get conclusive results these tests can take weeks or months to complete for low traffic&nbsp;sites.</p><p>If the product you are testing had bad usability from the start, you are just iterating on the fundamental problems. This type of testing won&rsquo;t help much with existing user frustrations, and removing those could give a much better&nbsp;outcome.</p><p>You can only test a limited number of elements. Testing too much at the same time might increase conversion but statistically you can know what helped the most, which makes it difficult to learn from the&nbsp;process.</p><p>It is by design an inefficient form of data collection. When doing multiple tests back-to-back, no information from the parallell tests can be used to draw conclusines about the other variables you may want to test in the&nbsp;future.</p></main>
      <footer>
        <small>© 2014–20 · <a href="https://webring.xxiivv.com/">Webring</small>
      </footer>